{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model for Actionable item classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from gensim import utils\n",
    "import gensim.parsing.preprocessing as gsp\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.test.utils import common_texts, get_tmpfile\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import utils as skl_utils\n",
    "from tqdm import tqdm\n",
    "\n",
    "import multiprocessing\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load data\n",
    "actions_df = pd.read_csv('actions.csv', names = ['action_sent'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>action_sent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Activate all who work with Transmission or have any good ideas on the subject.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Add more to your score by stopping in and picking up hefty load of construction supplies to win.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Add O'neal Winfee and George Smith to the attendees list.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Additionally, send me the payment schedule for Tenaska IV this month.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Adjust our purchase amount from each party based on the transport allocation.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1245</th>\n",
       "      <td>Write me note about what is going on and what issues you need my help to deal with when you send the rentroll.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1246</th>\n",
       "      <td>Write verification plans specifications and documentation today and send me.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1247</th>\n",
       "      <td>you have to expand on the maintenance tools.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1248</th>\n",
       "      <td>You have to resolve Enron's ongoing concerns at any cost.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1249</th>\n",
       "      <td>Your task is to deliver them to Janet for execution.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1250 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                         action_sent\n",
       "0                                     Activate all who work with Transmission or have any good ideas on the subject.\n",
       "1                   Add more to your score by stopping in and picking up hefty load of construction supplies to win.\n",
       "2                                                          Add O'neal Winfee and George Smith to the attendees list.\n",
       "3                                              Additionally, send me the payment schedule for Tenaska IV this month.\n",
       "4                                      Adjust our purchase amount from each party based on the transport allocation.\n",
       "...                                                                                                              ...\n",
       "1245  Write me note about what is going on and what issues you need my help to deal with when you send the rentroll.\n",
       "1246                                    Write verification plans specifications and documentation today and send me.\n",
       "1247                                                                    you have to expand on the maintenance tools.\n",
       "1248                                                       You have to resolve Enron's ongoing concerns at any cost.\n",
       "1249                                                            Your task is to deliver them to Janet for execution.\n",
       "\n",
       "[1250 rows x 1 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 1500\n",
    "actions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The tagged data available is only of one class i.e action class\n",
    "- So I will use one class classification.\n",
    "- One-class classification is a field of machine learning that provides techniques for outlier and anomaly detection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1. data cleaning:\n",
    "- convert to lower case\n",
    "  1. remove html tags\n",
    "  2. remove punctuation\n",
    "  3. remove extra white spaces\n",
    "  4. remove stop words\n",
    "  5. remove numerics\n",
    "  6. stemming\n",
    "  7. remove very short words\n",
    "  8. ignore non unicode characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_clean(sent):\n",
    "    sent = sent.lower()\n",
    "    sent = utils.to_unicode(sent)\n",
    "    for rule in cleaner:\n",
    "        sent = rule(sent)\n",
    "    return sent\n",
    "\n",
    "cleaner = [gsp.strip_tags, \n",
    "           gsp.strip_punctuation,\n",
    "           gsp.strip_multiple_whitespaces,\n",
    "           gsp.strip_numeric,\n",
    "           gsp.remove_stopwords, \n",
    "           gsp.strip_short, \n",
    "           gsp.stem_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "s1 = []\n",
    "for ele in actions_df[\"action_sent\"]:\n",
    "    s1.append(sent_clean(ele))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "actions_df['cleaned'] = s1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Featurization\n",
    "- i want the features to capture some context hence using Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the pretrained model from\n",
    "#https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "model1 = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srv1\\Anaconda3\\envs\\trainemail\\lib\\site-packages\\ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    }
   ],
   "source": [
    "w2v_words = list(model1.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                         | 0/1250 [00:00<?, ?it/s]C:\\Users\\srv1\\Anaconda3\\envs\\trainemail\\lib\\site-packages\\ipykernel_launcher.py:9: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  if __name__ == '__main__':\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 1250/1250 [11:17<00:00,  1.84it/s]\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors = []\n",
    "for sent in tqdm(actions_df['cleaned']):\n",
    "    sent_vec = np.zeros(300) # as word vectors are of 300 length\n",
    "    cnt_words =0 \n",
    "    for word in sent:\n",
    "        if word in w2v_words:\n",
    "            vec = model1.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training Auto Encoder \n",
    "I am using Auto Encoder to learn efficient data codings in an unsupervised manner. The aim of using autoencoder is to learn a representation (encoding) for the set of action sentence data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Layer structure of the auto encoder\n",
    "- Layer1: 300 features INPUT\n",
    "- Layer2: 600 features\n",
    "- Layer3: 150 features\n",
    "- Layer4: 600 features\n",
    "- Layer5: 300 features OUTPUT\n",
    "\n",
    "<br>\n",
    "Autoencoders are trained with the same data as input & output both. So, Layer 5 output is nothing but a reconstructed version of the input with some loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "auto_en = MLPRegressor(hidden_layer_sizes=(600,150,600))\n",
    "auto_en.fit(sent_vectors, sent_vectors)\n",
    "predicted_vec = auto_en.predict(sent_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\srv1\\Anaconda3\\envs\\trainemail\\lib\\site-packages\\sklearn\\base.py:434: FutureWarning: The default value of multioutput (not exposed in score method) will change from 'variance_weighted' to 'uniform_average' in 0.23 to keep consistent with 'metrics.r2_score'. To specify the default value manually and avoid the warning, please either call 'metrics.r2_score' directly or make a custom scorer with 'metrics.make_scorer' (the built-in scorer 'r2' uses multioutput='uniform_average').\n",
      "  \"multioutput='uniform_average').\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5776947222477959"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto_en.score(predicted_vec, sent_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Autoencoder is able to reconstruct only 57 % variance as per 'Regression accuracy'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. one-class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import OneClassSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_clf = OneClassSVM(gamma='scale', nu=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneClassSVM(cache_size=200, coef0=0.0, degree=3, gamma='scale', kernel='rbf',\n",
       "            max_iter=-1, nu=0.01, shrinking=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_clf.fit(sent_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 test metrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('test.csv')\n",
    "test_y = test['label']\n",
    "test_x = test['sentence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# detect outliers in the test set\n",
    "\n",
    "svm_yhat = model.predict(test_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " To evaluate the performance of the model as a binary classifier, we must change the labels in the test dataset from 0 and 1 for the majority and minority classes respectively, to +1 and -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_report(test_y ,svm_yhat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
